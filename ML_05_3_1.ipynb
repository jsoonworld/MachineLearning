{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Tree ensemble\n",
        "\n",
        "##Structured Data &  Unstructured Data\n",
        "- 정형데이터 -> 앙상블 러닝에 최적\n",
        "##ensemble learning\n",
        "\n",
        "- 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘\n",
        "\n",
        "\n",
        "##Random Forest\n",
        "\n",
        "- 랜덤 포레스트는 각 트리를 훈련하기 위한 데이터를 랜덤하게 만드는데, 이 데이터를 만드는 방법이 독특하다. 입련한 훈련 데이터에서 랜덤하게 샘플을 추출하여 훈련 데이터를 만든다. 이때 한 샘플이 중복되어 추출될 수도 있다.\n",
        "\n",
        "##boostrap sample\n",
        "\n",
        "- 1,000개 가방에서 100개씩 샘플을 뽑는다면 먼저 1개를 뽑고, 뽑았던 1개를 다시 가방에 넣는다. 이렇게 해서 만들어진 샘플을 boostrap sample이라고 한다."
      ],
      "metadata": {
        "id": "6wmlLHeS-UbG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KTDoPm4j98B-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##return_train_score = True\n",
        "-훈련 세트와 검증 세트의 점수를 같이 반환"
      ],
      "metadata": {
        "id": "uQsF52ZnA1Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "scores= cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU9Ht6c3AnAY",
        "outputId": "714ca017-67f0-4dab-e6f9-3aedfa792b1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfY6aL9cBIUB",
        "outputId": "bace44b6-acfe-4f41-f812-e45d5cac9016"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OOB (Out Of Bag)"
      ],
      "metadata": {
        "id": "Jzs0ly1qBsKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG94tJy2Bks_",
        "outputId": "c4661ca8-cc15-4e28-ff49-5c0861db7205"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extrea Tress\n",
        "- 랜덤 포레스트와 엑스트라 트리의 차이점은 부트스트램 샘플을 사용하지 않는다.\n",
        "- 결정 트리를 만들 때 전체 훈련 세트를 사용한다.\n",
        "- 노드를 분할할 때 가장 좋은 분할을 찾는 것이 아니라 무작위로 분할한다."
      ],
      "metadata": {
        "id": "XAlOoGOOB_LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3Km6uKlB5a-",
        "outputId": "593dc3a9-6320-4715-976c-4f0560f2d862"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys2PzwB8Cqv6",
        "outputId": "d5971340-59ff-4ad4-d8f5-0bfb94914235"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##gradient boosting\n",
        "- 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 하는 방법.\n",
        "\n",
        "- 사이킷런의 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정 트리를 100개 사용한다. 깊이가 얕은 결정 트리를 사용하기 때문에 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대할 수 있다.\n",
        "\n",
        "- 그레이디언트란 경사 하강법을 사용하여 트리를 앙상블에 추가한다."
      ],
      "metadata": {
        "id": "kGeuTOBJC5cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score= True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RKDFursC3KF",
        "outputId": "fe54a572-5c01-45b6-ff71-a19662e0c8c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "socres = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EzkYKsNELoo",
        "outputId": "0ba21664-b620-4216-a259-85a4261ec4ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izrzqwazEhGp",
        "outputId": "7d3e38d9-134b-4da8-9f0c-a1514e63e85f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Histogram-based Gradient Boosting\n",
        "\n",
        "- 정형 데이터를 다루는 머신러닝 알고리즘 중에 가장 인기가 높은 알고리즘이다."
      ],
      "metadata": {
        "id": "wf4knxsvFXRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Bxr8e2EqAX",
        "outputId": "189a923a-fe6d-4563-8f81-f38c9b2f37c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0cPehy_GBOl",
        "outputId": "8fa04fa0-f8a2-49ff-a3ac-d70c33c55435"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK90v-CLGiyr",
        "outputId": "d5aaa1bd-a7ef-4d87-cbe0-e205db490b5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scoes = cross_validate(xgb, train_input, train_target, return_train_score=True)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKGVfS54GoXR",
        "outputId": "f92f6335-ba9a-49d8-a667-cabfde042603"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_3gGnSQHMs4",
        "outputId": "213badcc-a6e7-4b82-fcc6-8ddeea61be73"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9338079582727165 0.8789710890649293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##앙상블 학습을 통한 성능 향상\n",
        "\n",
        "- 랜덤 포레스트는 가장 대표적인 앙상블 학습 알고리즘이다. 성능이 좋고 안정적이기 때문에 첫 번째로 시도해 볼 수 있는 앙상블 학습 중 하나이다. 랜덤 포레스트는 결정 트리를 훈련하기 위해 부트스트랩 샘플을 만들고 전체 특성 중 일부를 랜덤하게 선택하여 결정 트리를 만든다. \n",
        "\n",
        "- 엑스트라 트리는 랜덤 포레스트와 매우 비슷하지만 부트스트랩 샘플을 사용하지 않고 노드를 분할할 때 최손이 아니라 랜덤하게 분할한다. 이런 특징 때문에 랜덤 포레스트보다 훈련 속도가 빠르지만 보통 더 많은 트리가 필요하다.\n",
        "\n",
        "- 그레이디언트 부스팅은 깊이가 얕은 트리를 연속적으로 추가하여 손실 함수를 최소하하는 앙상블 방법이다. 성능이 뛰어나지만 병렬로 훈련할 수 없기 때문에 랜덤 포레스트나 엑스트라 트리보다 훈련 속도가 조금 느리다. 그레이디언트 부스팅에서 학습률 매개변수를 조정하여 모델의 복잡도를 제어할 수 있다. 학습률 매개변수가 크면 복잡하고 훈련 세트에 과대적합된 모델을 얻을 수 있다.\n",
        "\n",
        "- 가장 뛰어난 앙상블 학습으로 평가받는 히스토그램 기반 그레이디어느 부스팅 알고리즘을 알아봤다. 히스토그램 기반 그레이디언트 부스팅은 훈련 데이터를 256개의 구간으로 변환하여 사용하기 때문에 노드 분할 속도가 매우 빠르다. 코랩에는 사이킷런뿐만 아니라 히스토그램 기반 그레이디언트 부스팅 라이브러리인 XGBoost 와 LightGBM이 이미 설치되어 있어 바로 시험해 볼 수 있다. "
      ],
      "metadata": {
        "id": "Eqqf6OyaIDzG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaQgnUYSHeRe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}